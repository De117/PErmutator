\documentclass[11pt,final,conference,a4paper]{IEEEtran}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[noadjust]{cite}
\usepackage{url}
\usepackage[dvips]{graphicx}

\begin{document}

\IEEEoverridecommandlockouts

\title{Fine grained permutation of text code in PE files}

\author{
	\authorblockN{Bruno Humić, Stjepan Groš}
	\authorblockA{
		Faculty of Electrical and Computing Engineering \\
		University of Zagreb\\
		Unska bb, 10000 Zagreb, Croatia \\
		E-Mail: bruno.humic@gmail.com, stjepan.gros@fer.hr}}

\maketitle

\begin{abstract}
Memory corruption is one of the oldest security vulnerabilities
that is still very common today. It allows attackers to gain full
control of victims computer. Crucial in the step of gaining control
is for attacker to know memory layout of a process. There are a
number of protection mechanisms developed to counter this threat,
one of which are randomization mechanisms that make process image
layout unpredictable for attacker. Randomization based security
mechanisms had a major impact on dealing with memory corruption
vulnerabilities but the threat still remains. In this paper we
describe work started on a new randomization security mechanism
whose goal is to rearrange memory blocks in the code section of a
PE file. In that way, we strive to achieve higher security levels
of a system by making process layout even more unpredictable for
the attackers.
\end{abstract}

\begin{keywords}
PE file format, computer security, operating systems, ASLR, DEP, ASLP, randomization, memory corruption, permutation, control flow graph, Microsoft Windows
\end{keywords}

\section{Introduction}
\label{sec:intro}

Species in the nature use diversity in order to combat different
threats. In other words, if a threat manages to infect one specimen
it want be able to infect many others because all of them are
different. In computer networks, when a threat compromises one
machine, it will probably compromises many others too because they
are all identical, or almost identical.

This is a know premise, and there are attempts to apply principles
from the nature in a computer networks. Yet, we are still far away
from a satisfactory solution.

The paper is structured as follows. First, we review related work
in Section \ref{sec:architecture}. We also list shortcomings of
existing approaches in that section. Then, in Section \ref{sec:design}
we describe the idea behind our solution, and its design and
implementation. In Section \ref{sec:testing} we give results of
different tests we performed on PErmutator. Finally, we conclude
paper in Section \ref{sec:conclusions}.

\section{Related work}
\label{sec:architecture}
Numerous projects and research has been done in the area of software diversity and we will use this section to discuss and describe some of them.

Before going to concrete examples of software diversity, we should note that there are two approaches to the process of software diversification:
\begin{itemize}
\item Pre-distribution approach: The main idea behind this approach is that all diversification action takes place before the program is shipped to end users. Therefore, the majority of diversification in this approach happens in the compiler. Certain advantages of this approach are as follows:
\begin{itemize}
\item Portability: Compilers are tools that are highly sophisticated and costly to produce and maintain. The reason for this is that compilers support multiple instruction sets which allows them to produce end user programs for various platforms. By adding the diversification feature to a compiler, diversified programs can be available on all platforms that are supported by the compiler.
\item Wide transformation range: Since all compilers do sequences of code transformation passes in which instructions are selected and scheduled, it is relatively easy to add randomization transformations to existing passes. Also, the compilers avoid the need for disassembly. This is a significant advantage because the transformation from source code to object code is lossy which makes the perfect recovery of the original program control flow impossible.
\end{itemize}
However, there are some disadvantages when talking about compiler based diversification. If all the diversification happens before the product is shipped, there is an increased cost in the distribution because every client must download a separate and unique product variant. This requires a distribution system which must maintain a large inventory of program variants such that downloads start without delay. Also, the big problem with this approach is patching. Since every client has an unique program variant, the vendor must supply patches that are customized for each individual copy.
\item Post-distribution approach: In this approach all the diversification happens at the clients. The main advantage of this approach is that there is no need to change the current way in which the programs are distributed to clients. Also, when using this approach vendors avoid the cost of diversifying each program copy. However, the client systems must be powerful enough to run the diversification engine.

The disadvantages of this approach are as follows:
\begin{itemize}
\item Client Side attacks: The diversification process on the client can be disabled by malware.
\item Same diversification engine: Since all diversification happens on the client, the client must contain a copy of the engine itself. This allows attackers to analyze the engine and make it possible for attacks.
\end{itemize}
\end{itemize}
In the remaining part of this section we discuss some concrete diversification implementations. Since there are many diversification projects out there, we will be focusing on those that are highly in use today and those which share some common things with the diversification tool we are building.

The most popular randomization security mechanism today is probably ASLR. In fact, it is the only diversified security mechanism that is currently deployed. Before ASLR, the base of code and data segments were always loaded at the same virtual memory addresses. The way ASLR works is that it randomizes the base address of code and data segments. This means that the stack, heap, statically allocated data and the images base address are randomly chosen. By doing this, ASLR significantly aggravates memory corruption, code injection and code reuse attacks. ASLR can be classified as a compiler based or pre-distribution diversity mechanism. The reason for this is because ASLR depends on the compiler which must generate position independent code so that the base address randomization can be carried out.

However, ASLR has certain drawbacks. It can be easily bypassed via information leakage. Also it has very low entropy on 32-bit system which means it can be defeated via brute-force attacks. The reason for low entropy in ASLR is due to the fact that it randomizes only the two high order bytes of the address. Another major disadvantage of ASLR is the fact that it only allows coarse grained permutation. What this means is that ASLR will shift all the addresses by the same amount so that relative distances inside the image remain unchanged. This allows attackers to infer the entire memory layout of the process just by disclosing a single code address.

Another interesting project in software diversity is Address Space Layout Permutation (ASLP). The fine grained permutation tool that we are creating here is very similar to ASLP with the difference that ASLP is focused on the Linux platform. ASLP is mostly a post-distribution diversification mechanism because it's main part is a binary rewriting tool that operates in the user space. Also, ASLP provides both user and kernel level randomization.

The created binary rewriting tool is the foundation for the user level randomization process. This tool comprises of two major phases:
\begin{enumerate}
\item Coarse grained permutation: The goal of this phase is to shift the code and data segments according to the offset values given by the user.
\item Fine grained permutation: The goal of fine grained permutation in the ASLP project is to randomly change the order of functions and variables inside the code and data segments.
\end{enumerate}
In the kernel level permutation part, ASLP is very similar to ASLR. Just like ASLR, ASLP randomizes the location of stack, heap and shared libraries. In order to do so, the Linux kernel had to be modified. This is also the part where our fine grained permutation tool differs from ASLP because we aren't providing diversification on the kernel level. This is due to the fact that we are creating a tool for Microsoft Windows operating system whose kernel is closed to outside modifications.
The last thing to note about ASLP is that it has very low performance overhead (less than 1\%) and it allows randomization of 20 bits in the addresses of code, data and shared library segments.

In order for this section to be complete, we would like to draw attention to one more pre-distribution based diversification mechanism. 

It is well known that most compilers can execute a program to discover "hot" and "cold" code paths. Also, it is well known that diversification tends to make programs run slower. This brings up the idea that compilers can be used in the diversification process in a way to reduce the amount of diversification for "hot" code parts and direct the diversification towards "cold" code parts. By doing so, the performance overhead is significantly lowered.

Homescu et al. used this fact to create a profile guided diversity engine based on NOP insertion. The main idea behind the project is to insert most NOP instruction inside the "cold" code area. In that way the target binary gets randomized but the performance overhead is kept to a minimum. 


\section{PErmutator design and implementation}
\label{sec:design}

At this moment, out fine grained permutation engine is following a post-distribution diversification approach. The main part of the project is a binary rewriting tool which performs basic block reordering. This binary rewriting tool can be divided into several key parts:
\begin{enumerate}
\item Disassembler
\item Control flow graph creation
\item Permutation engine
\end{enumerate}

Heuristics

Problems

PErmutaror Flow (graph generation, \ldots)

\section{Testing and validation}
\label{sec:testing}

\subsection{Validation}

Running vulnerable application to test if protection is better than ASLR.

\subsection{Performance}

Loading and executing application

Running application performance penalties

\section{Conclusions and Future Work}
\label{sec:conclusions}

\bibliographystyle{IEEEtran}
\bibliography{bibliography}

% Temporary fix until there are some references in the text
\nocite{arscryptolocker}

\end{document}
